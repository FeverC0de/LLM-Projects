{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Person Bot Version 0.1\n",
    "\n",
    "Hey! Created this template for create a basic bot which you can customize with a system prompt, and can generate images. Feel free to use this to create a chatbot clone of yourself or your friends(with their permission ofc) :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ```dotenv ``` and  ```load_dotenv``` to use and load enviromental variables but mainly to load up the API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading ENV Variables\n",
    "\n",
    "load_dotenv(override = True)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```load_dotenv``` loads up the .env file.\n",
    "\n",
    "```os.getenv(\"...\")``` retrieves the '...' value to a variable openai_api_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'gpt-4o'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets openai object and specifies what model to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a System Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System prompt is needed to define how the AI Model behaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"[PUT YOUR CHARACTER DESCRIPTION HERE]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Generate Image Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```import base64```\n",
    "Used to encode and decode date in Base64 format\n",
    "\n",
    "```from io import BytesIO```\n",
    "\n",
    "```io``` allows you to handle streams of data\n",
    "\n",
    "```BytesIO``` Creates an in-memory binary stream, treating bytes as a file-like object. Allowing to handle the image data without writing to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocks():\n",
    "    image_response = openai.images.generate(\n",
    "        model = \"dall-e-3\",\n",
    "        prompt = \"An image of a nice pebble or rock, with interesting shapes, held by a firm masculine hand, HD, iphone camera\",\n",
    "        size = \"1024x1024\",\n",
    "        n = 1,\n",
    "        response_format= \"b64_json\")\n",
    "    \n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retrieving image data\n",
    "``` image_base64 = image_response.data[0].bs64_json```\n",
    "\n",
    "Get's the image data from the image_response object\n",
    "\n",
    "```image_response.data[0]```\n",
    "\n",
    "accesses the image data index from the image_response object\n",
    "\n",
    "```.bs64_json``` \n",
    "\n",
    "contains the image data in JSON format\n",
    "\n",
    "##### Converting image data to binary\n",
    "\n",
    "```base64.b64decode(image_base64)```\n",
    "\n",
    "Decodes string into binary image data\n",
    "\n",
    "##### Loading image\n",
    "\n",
    "```return Image.open(BytesIO(image_data))```\n",
    "\n",
    "```BytesIO(image_data)``` \n",
    "\n",
    "Creates an in-memory binary stream (file - like object) from the binary image data (image)data\n",
    "\n",
    "```Image.open()``` \n",
    "\n",
    "From PIL library, which opens an image from a file-like object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool Dictionary\n",
    "\n",
    "Creates a dictionary, containing information about a specified tool. Rocks is a place holder, you can rename it based on your function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\" : \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"rocks\",\n",
    "            \"description\": \"Generates an image of a nice image or rock held by you.\",\n",
    "            \"parameters\": {} \n",
    "        }\n",
    "    }\n",
    "]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_call(message):\n",
    "    if not message.tool_calls:\n",
    "        return {\"role\": \"tool\", \"tool_call_id\": None, \"content\": \"No tool call found.\"}\n",
    "\n",
    "    tool_call = message.tool_calls[0]\n",
    "    function_name = tool_call.function.name\n",
    "\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"content\": \"\"\n",
    "    }\n",
    "\n",
    "    if function_name == \"rocks\":\n",
    "        image = rocks()  \n",
    "        response[\"content\"] = \"Look at this cool rock i found\"\n",
    "        return response, image\n",
    " \n",
    "    response[\"content\"] = f\"Unknown function: {function_name}\"\n",
    "    return response, None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```if not message.tool_calls```\n",
    "\n",
    "Checks to see if message.tool_calls exists or is empty. If not:\n",
    "\n",
    "```return {\"role\": \"tool\", \"tool_call_id\": None, \"content\": \"No tool call found.\"}```\n",
    "\n",
    "Which creates a dictionary, showing that it's coming from a tool and that there is no ID as no tool exits, and returns a message showing that nothing was called"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```tool_call = message.tool_calls[0]```\n",
    "\n",
    "Retrieves first tool call from message.tool_calls, get's the function name and stores it in ```function_name```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```response = {...}```\n",
    "\n",
    "Creates a response dictionary, like before, content is left empty to be changed later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```if function_name == \"rocks\":```\n",
    "performs what the ufnction is supposed to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```response[\"content\"] = f\"Unknown function: {function_name}\"```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the response dictionary with the content text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "\n",
    "def chat(history):\n",
    "    messages = [{\"role\":\"system\", \"content\":system_prompt}] + history\n",
    "    response = client.chat.completions.create(\n",
    "        model = MODEL,\n",
    "        messages = messages,\n",
    "        tools = tools\n",
    "    )\n",
    "\n",
    "    image = None\n",
    "\n",
    "    if response.choices[0].finish_reason == \"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        tool_response, image = handle_tool_call(message)\n",
    "        messages.append(message)\n",
    "        messages.append(tool_response)\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model = \"gpt-4\",\n",
    "            messages = messages\n",
    "        )\n",
    "    \n",
    "    reply = response.choices[0].message.content\n",
    "    history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "    return history, image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```response.choices[0].finish_reason = \"tool_calls```\n",
    "\n",
    "Checks if response has a request to call a tool\n",
    "\n",
    "```tool_response, image = handle_tool_call(message)```\n",
    "\n",
    "Returns response and image from handle_tool_call function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradio UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UI made with gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7907\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7907/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py\", line 2051, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py\", line 1598, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2461, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 962, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\utils.py\", line 883, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Nick-Uni\\AppData\\Local\\Temp\\ipykernel_23700\\965181427.py\", line 15, in chat\n",
      "    tool_response, image = handle_tool_call(message)\n",
      "  File \"C:\\Users\\Nick-Uni\\AppData\\Local\\Temp\\ipykernel_23700\\1864237044.py\", line 15, in handle_tool_call\n",
      "    image = rocks()\n",
      "  File \"C:\\Users\\Nick-Uni\\AppData\\Local\\Temp\\ipykernel_23700\\869997017.py\", line 9, in rocks\n",
      "    image_base64 = image_response.data[0].bs64_json\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\main.py\", line 891, in __getattr__\n",
      "    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\n",
      "AttributeError: 'Image' object has no attribute 'bs64_json'. Did you mean: 'b64_json'?\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py\", line 2051, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py\", line 1598, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2461, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 962, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\utils.py\", line 883, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Nick-Uni\\AppData\\Local\\Temp\\ipykernel_23700\\965181427.py\", line 15, in chat\n",
      "    tool_response, image = handle_tool_call(message)\n",
      "  File \"C:\\Users\\Nick-Uni\\AppData\\Local\\Temp\\ipykernel_23700\\1864237044.py\", line 15, in handle_tool_call\n",
      "    image = rocks()\n",
      "  File \"C:\\Users\\Nick-Uni\\AppData\\Local\\Temp\\ipykernel_23700\\869997017.py\", line 9, in rocks\n",
      "    image_base64 = image_response.data[0].bs64_json\n",
      "  File \"c:\\Users\\Nick-Uni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\main.py\", line 891, in __getattr__\n",
      "    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\n",
      "AttributeError: 'Image' object has no attribute 'bs64_json'. Did you mean: 'b64_json'?\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500)\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Talk To Ahmad:\")\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def do_entry(message, history):\n",
    "        history += [{\"role\":\"user\", \"content\":message}]\n",
    "        return \"\", history\n",
    "\n",
    "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, image_output]\n",
    "    )\n",
    "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
